{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frmWiki = wikipedia.WikipediaPage('History_of_Western_civilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikiText = frmWiki.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want to use the standard english-language parser.\n",
    "parser = spacy.load('en')\n",
    "\n",
    "# Parsing text.\n",
    "text = parser(wikiText)\n",
    "\n",
    "# Dividing the text into sentences and storing them as a list of strings.\n",
    "sentences=[]\n",
    "for span in text.sents:\n",
    "    # go from the start to the end of each span, returning each token in the sentence\n",
    "    # combine each token using join()\n",
    "    sent = ''.join(text[i].string for i in range(span.start, span.end)).strip()\n",
    "    sentences.append(sent)\n",
    "\n",
    "# Creating the tf-idf matrix.\n",
    "counter = TfidfVectorizer(lowercase=False, \n",
    "                          stop_words=None,\n",
    "                          ngram_range=(1, 1), \n",
    "                          analyzer=u'word', \n",
    "                          max_df=.5, \n",
    "                          min_df=1,\n",
    "                          max_features=None, \n",
    "                          vocabulary=None, \n",
    "                          binary=False)\n",
    "\n",
    "#Applying the vectorizer\n",
    "data_counts=counter.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0015664193893260758, 'In Asia, China was defeated by Britain in the Opium War and later Britain and France in the Arrow War, forcing it to open up to trade with the West.'), (0.0014732242104492047, \"Canada was unique in the British Empire in that it had a French-speaking province, Quebec, which Britain had gained rule over in the Seven Years' War.\\n\\n\\n=\"), (0.0014102954682504935, 'The major Western players in this New Imperialism were Britain, Russia, France, Germany, Italy, and the United States.')]\n"
     ]
    }
   ],
   "source": [
    "# Calculating similarity\n",
    "similarity = data_counts * data_counts.T\n",
    "\n",
    "# Identifying the sentence with the highest rank.\n",
    "nx_graph = nx.from_scipy_sparse_matrix(similarity)\n",
    "ranks=nx.pagerank(nx_graph, alpha=.85, tol=.00000001)\n",
    "\n",
    "rankedSents = sorted(((ranks[i],s) for i,s in enumerate(sentences)),\n",
    "                reverse=True)\n",
    "print(rankedSents[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final list of tokens\n",
    "words = []\n",
    "# used to make sure there are not duplicates\n",
    "wordTracker = []\n",
    "# Removing stop words and punctuation, \n",
    "# then getting a list of all unique words in the text\n",
    "for word in text: \n",
    "    if (\n",
    "        word.is_stop==False \n",
    "        and (word.pos_=='NOUN' or word.pos_=='ADJ') \n",
    "        and (word.text not in wordTracker)\n",
    "        and (len(word.text) > 3)\n",
    "    ):\n",
    "        wordTracker.append(word.text)\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency=pd.DataFrame(columns=words,index=words,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(text): \n",
    "    word=word\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in text_filt]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "        end=max(0,len(text)-(len(text)-(i+5)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=text[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in text_filt for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency.loc[word,neighbors]=adjacency.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.00042936882782308326, reading), (0.00042936882782308326, References), (0.00042936882782308326, View), (0.00042936882782308326, civilizationMediaCivilization), (0.00042936882782308326, History)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersmyth/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "#nx_words = nx.from_numpy_matrix(adjacency.values())\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "rankedWrds = sorted(((ranks[i],s) for i,s in enumerate(words)),\n",
    "                reverse=True)\n",
    "print(rankedWrds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Asia, China was defeated by Britain in the Opium War and later Britain and France in the Arrow War, forcing it to ____ up to trade with the West.\n",
      "Answer: open\n",
      "\n",
      "Canada was unique in the British ____ in that it had a French-speaking province, Quebec, which Britain had gained rule over in the Seven Years' War.\n",
      "\n",
      "\n",
      "=\n",
      "Answer: Empire\n",
      "\n",
      "The major Western ____ in this New Imperialism were Britain, Russia, France, Germany, Italy, and the United States.\n",
      "Answer: players\n",
      "\n",
      "Germany was also forced to give up the lands it had gained in the Franco-Prussian War to France, accept responsibility for the war, reduce its military and pay ____ to Britain and France.\n",
      "Answer: reparations\n",
      "\n",
      "Missionaries sent from Ireland by the Pope helped to convert England to Christianity in the 6th century as well, restoring that ____ as the dominant in Western Europe.\n",
      "Answer: faith\n",
      "\n",
      "The years ____ Britain's victory in the Napoleonic Wars were a period of expansion for the United Kingdom and its former American colonies, which now made up the United States.\n",
      "Answer: following\n",
      "\n",
      "The first ____ state in the West was established in Italy.\n",
      "Answer: totalitarian\n",
      "\n",
      "After several years, however, Southern states began rejoining the ____ as their populations pledged loyalty to the United States government, and in 1877 Reconstruction as this period was called, came to an end.\n",
      "Answer: Union\n",
      "\n",
      "The lands of North and ____ America, ____ Africa, Australia and New Zealand became first part of European Empires and then home to new Western nations, while Africa and Asia were largely carved up between Western powers.\n",
      "Answer: South\n",
      "\n",
      "The first colonies to gain ____ were in Asia.\n",
      "Answer: independence\n",
      "\n",
      "The treaty ending the war granted ____ to the colonies, which became The United States of America.\n",
      "Answer: independence\n",
      "\n",
      "Following the Fall of Singapore in 1941, Australia turned to the United States for military aid against the Japanese Empire and Australia and New Zealand joined the United States in the ____ military alliance in the early 1950s and contributed troops to anti-communist conflicts in South-East Asia in the 1950s, 1960s and 1970s.\n",
      "Answer: ANZUS\n",
      "\n",
      "Germany also established two colonies in ____ Africa, and Portugal had one as well.\n",
      "Answer: West\n",
      "\n",
      "Two problems faced by Britain in this period were the ____ of British rule in Ireland and Britain's falling behind Germany and the United States in industrial production.\n",
      "\n",
      "\n",
      "=== British dominions:\n",
      "Answer: resentment\n",
      "\n",
      "The ____ and Italians were the two dominant powers in East Africa, although France also had a colony there.\n",
      "Answer: British\n",
      "\n",
      "The loss of overseas colonies partly also led many Western nations, particularly in continental Europe, to focus more on European, rather than global, politics as the European ____ rose as an important entity.\n",
      "Answer: Union\n",
      "\n",
      "The war ended with an American victory, and Mexico had to cede all its northern ____ to the United States, and recognize the independence of California, which had revolted against Mexico during the war.\n",
      "Answer: territories\n",
      "\n",
      "The changes in Central and Eastern Europe led to ____ for reform in the Soviet Union itself.\n",
      "Answer: calls\n",
      "\n",
      "The ____ has contributed a great many technological, political, philosophical, artistic and religious aspects to modern international culture: having been a crucible of Catholicism, Protestantism, democracy, industrialisation; the first major civilisation to seek to abolish slavery during the 19th century, the first to enfranchise women (beginning in Australasia at the end of the 19th century) and the first to put to use such technologies as steam, electric and nuclear power.\n",
      "Answer: West\n",
      "\n",
      "After the war, Communist parties in Western Europe increased in prestige and number, especially in Italy and France, leading many to ____ the whole of Europe would become Communist.\n",
      "Answer: fear\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsTested=[]\n",
    "maxSent = 20\n",
    "for index,sentWithRank in enumerate(rankedSents):  \n",
    "    if index == maxSent:\n",
    "        break\n",
    "    sentence=sentWithRank[1]\n",
    "    for w in rankedWrds:\n",
    "        rankedWord=str(w[1])\n",
    "        \n",
    "        if (' '+rankedWord+' ' in sentence) and (rankedWord not in wordsTested):\n",
    "            blankSent = sentence.replace(' '+rankedWord+' ',' ____ ')\n",
    "            print (blankSent)\n",
    "            print ('Answer: {}\\n'.format(rankedWord))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsTested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ee59cc6decc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwordTokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankedSents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilteredSent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordTokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-ee59cc6decc1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwordTokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrankedSents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilteredSent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordTokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words\n",
    "wordTokens = word_tokenize(rankedSents[0][1])\n",
    "filteredSent = [w for w in wordTokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "theory\n",
      "is\n",
      "that\n",
      "in\n",
      "feature\n",
      "searches,\n",
      "it\n",
      "is\n",
      "easy\n",
      "to\n",
      "spot\n",
      "the\n",
      "target,\n",
      "or\n",
      "if\n",
      "it\n",
      "is\n",
      "absent,\n",
      "because\n",
      "of\n",
      "the\n",
      "difference\n",
      "in\n",
      "color\n",
      "between\n",
      "the\n",
      "target\n",
      "and\n",
      "the\n",
      "distractors.\n"
     ]
    }
   ],
   "source": [
    "for wrd in str(rankedSents[0][1]).split():\n",
    "    print (wrd)\n",
    "    \n",
    "    [item for item in a if ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
